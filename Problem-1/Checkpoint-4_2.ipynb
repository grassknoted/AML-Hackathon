{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Dataset-1/selfie_dataset.txt\"#join(\"..\", \"..\", \"Dataset-1\", \"selfie_dataset.txt\")\n",
    "image_path = \"../Dataset-1/images\"#join(\"..\", \"..\", \"Dataset-1\", \"selfie_dataset.txt\")#join(\"..\", \"..\", \"Dataset-1\", \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>score</th>\n",
       "      <th>partial_faces</th>\n",
       "      <th>is_female</th>\n",
       "      <th>baby</th>\n",
       "      <th>child</th>\n",
       "      <th>teenager</th>\n",
       "      <th>youth</th>\n",
       "      <th>middle_age</th>\n",
       "      <th>senior</th>\n",
       "      <th>...</th>\n",
       "      <th>curly_hair</th>\n",
       "      <th>straight_hair</th>\n",
       "      <th>braid_hair</th>\n",
       "      <th>showing_cellphone</th>\n",
       "      <th>using_earphone</th>\n",
       "      <th>using_mirror</th>\n",
       "      <th>braces</th>\n",
       "      <th>wearing_hat</th>\n",
       "      <th>harsh_lighting</th>\n",
       "      <th>dim_lighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00a454da495e11e28a7322000a1fa414_6</td>\n",
       "      <td>3.901</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00cddb96ac4c11e3a30212279ba1b65f_6</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01cdd7aa1a1a11e2aaa822000a1fb0dd_6</td>\n",
       "      <td>4.243</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_name  score  partial_faces  is_female  baby  \\\n",
       "0  00a454da495e11e28a7322000a1fa414_6  3.901              1          1    -1   \n",
       "1  00cddb96ac4c11e3a30212279ba1b65f_6  4.385              1          1    -1   \n",
       "2  01cdd7aa1a1a11e2aaa822000a1fb0dd_6  4.243             -1          1    -1   \n",
       "\n",
       "   child  teenager  youth  middle_age  senior      ...       curly_hair  \\\n",
       "0     -1        -1      1          -1      -1      ...               -1   \n",
       "1     -1        -1     -1          -1      -1      ...               -1   \n",
       "2     -1         1     -1          -1      -1      ...               -1   \n",
       "\n",
       "   straight_hair  braid_hair  showing_cellphone  using_earphone  using_mirror  \\\n",
       "0             -1          -1                 -1              -1            -1   \n",
       "1             -1          -1                 -1              -1            -1   \n",
       "2             -1          -1                 -1              -1            -1   \n",
       "\n",
       "   braces  wearing_hat  harsh_lighting  dim_lighting  \n",
       "0      -1           -1              -1            -1  \n",
       "1      -1           -1              -1            -1  \n",
       "2      -1           -1              -1            -1  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\n",
    "    \"image_name\", \"score\", \"partial_faces\" ,\"is_female\" ,\"baby\" ,\"child\" ,\"teenager\" ,\"youth\" ,\"middle_age\" ,\"senior\" ,\"white\" ,\"black\" ,\"asian\" ,\"oval_face\" ,\"round_face\" ,\"heart_face\" ,\"smiling\" ,\"mouth_open\" ,\"frowning\" ,\"wearing_glasses\" ,\"wearing_sunglasses\" ,\"wearing_lipstick\" ,\"tongue_out\" ,\"duck_face\" ,\"black_hair\" ,\"blond_hair\" ,\"brown_hair\" ,\"red_hair\" ,\"curly_hair\" ,\"straight_hair\" ,\"braid_hair\" ,\"showing_cellphone\" ,\"using_earphone\" ,\"using_mirror\", \"braces\" ,\"wearing_hat\" ,\"harsh_lighting\", \"dim_lighting\"\n",
    "]\n",
    "df_image_details = pd.read_csv(data_path, names=headers, delimiter=\" \")\n",
    "df_image_details.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_details = df_image_details[df_image_details.is_female != 0]\n",
    "df_image_details.replace(to_replace=-1, value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = df_image_details.image_name.values.copy()\n",
    "image_scores = df_image_details[headers[1]].values.copy()\n",
    "image_attrs = df_image_details[headers[2:]].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [join(image_path, iname) + '.jpg' for iname in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train, image_paths_test = image_paths[:-1000], image_paths[-1000:]\n",
    "image_attrs_train, image_attrs_test = image_attrs[:-1000], image_attrs[-1000:]\n",
    "image_scores_train, image_scores_test = image_scores[:-1000], image_scores[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y1 = self.y[0][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y2 = self.y[1][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        # read your data here using the batch lists, batch_x and batch_y\n",
    "        x = [self.read_image(filename) for filename in batch_x] \n",
    "        y1 = [atrributes for atrributes in batch_y1]\n",
    "        y2 = [atrributes for atrributes in batch_y2]\n",
    "        return [np.array(x), np.array(x)], [np.array(y1), np.array(y2)]\n",
    "    \n",
    "    def read_image(self, fname):\n",
    "        im = cv2.imread(fname)\n",
    "        im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        return im / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import resnet50\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Input, Flatten, concatenate, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npc/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_rnet = load_model(\"resnet50.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_rnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = Dense(1024, activation='relu')(model_rnet.get_layer('avg_pool').output)\n",
    "model_classification = Dropout(0.5)(model_classification)\n",
    "\n",
    "model_classification = Dense(512, activation='relu')(model_classification)\n",
    "\n",
    "model_classification = Dense(36, activation='sigmoid', name='classification')(model_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression_input = Input((224, 224, 3), name='input_regression')\n",
    "model_regression = Conv2D(16, 3)(model_regression_input)\n",
    "model_regression = MaxPool2D()(model_regression)\n",
    "\n",
    "model_regression = Conv2D(24, 5)(model_regression)\n",
    "model_regression = MaxPool2D()(model_regression)\n",
    "\n",
    "model_regression = Conv2D(32, 5)(model_regression)\n",
    "model_regression = MaxPool2D()(model_regression)\n",
    "\n",
    "model_regression = Flatten()(model_regression)\n",
    "model_regression = Dense(128)(model_regression)\n",
    "\n",
    "model_regression = concatenate([model_regression, model_classification])\n",
    "\n",
    "model_regression = Dense(1, name='regression')(model_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[model_rnet.input, model_regression_input], outputs=[model_classification, model_regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_regression (InputLayer)   (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 222, 222, 16) 448         input_regression[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 111, 111, 16) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 107, 107, 24) 9624        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 53, 53, 24)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 49, 49, 32)   19232       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 24, 24, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 18432)        0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 36)           18468       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          2359424     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 164)          0           dense_6[0][0]                    \n",
      "                                                                 classification[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            165         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 28,618,049\n",
      "Trainable params: 5,030,337\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'regression': 'mean_squared_error',\n",
    "        'classification': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics=[\n",
    "        'accuracy'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageGenerator(image_paths_train, (image_attrs_train, image_scores_train), batch_size=128)\n",
    "test_gen = ImageGenerator(image_paths_test, (image_attrs_test, image_scores_test), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44227, 1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = len(image_paths_train)\n",
    "test_len = len(image_paths_test)\n",
    "train_len, test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "345/345 [==============================] - 270s 781ms/step - loss: 12.5174 - classification_loss: 0.4885 - regression_loss: 12.0289 - classification_acc: 0.8355 - regression_acc: 4.3026e-04 - val_loss: 0.8073 - val_classification_loss: 0.3461 - val_regression_loss: 0.4612 - val_classification_acc: 0.8316 - val_regression_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80734, saving model to chpt-4_2.hdf5\n",
      "Epoch 2/200\n",
      "345/345 [==============================] - 263s 764ms/step - loss: 0.5436 - classification_loss: 0.3002 - regression_loss: 0.2434 - classification_acc: 0.8759 - regression_acc: 5.2084e-04 - val_loss: 0.6198 - val_classification_loss: 0.3069 - val_regression_loss: 0.3129 - val_classification_acc: 0.8852 - val_regression_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80734 to 0.61983, saving model to chpt-4_2.hdf5\n",
      "Epoch 3/200\n",
      "345/345 [==============================] - 264s 765ms/step - loss: 0.5086 - classification_loss: 0.2881 - regression_loss: 0.2205 - classification_acc: 0.8797 - regression_acc: 5.6613e-04 - val_loss: 0.5796 - val_classification_loss: 0.3053 - val_regression_loss: 0.2743 - val_classification_acc: 0.8752 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61983 to 0.57959, saving model to chpt-4_2.hdf5\n",
      "Epoch 4/200\n",
      "345/345 [==============================] - 261s 756ms/step - loss: 0.4933 - classification_loss: 0.2815 - regression_loss: 0.2118 - classification_acc: 0.8816 - regression_acc: 5.2084e-04 - val_loss: 0.5763 - val_classification_loss: 0.2987 - val_regression_loss: 0.2776 - val_classification_acc: 0.8930 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57959 to 0.57632, saving model to chpt-4_2.hdf5\n",
      "Epoch 5/200\n",
      "345/345 [==============================] - 257s 744ms/step - loss: 0.4833 - classification_loss: 0.2786 - regression_loss: 0.2047 - classification_acc: 0.8824 - regression_acc: 5.4348e-04 - val_loss: 0.5914 - val_classification_loss: 0.3227 - val_regression_loss: 0.2687 - val_classification_acc: 0.8679 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57632\n",
      "Epoch 6/200\n",
      "345/345 [==============================] - 257s 746ms/step - loss: 0.4750 - classification_loss: 0.2757 - regression_loss: 0.1992 - classification_acc: 0.8836 - regression_acc: 5.8877e-04 - val_loss: 0.6103 - val_classification_loss: 0.3253 - val_regression_loss: 0.2850 - val_classification_acc: 0.8839 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.57632\n",
      "Epoch 7/200\n",
      "345/345 [==============================] - 257s 745ms/step - loss: 0.4478 - classification_loss: 0.2683 - regression_loss: 0.1795 - classification_acc: 0.8860 - regression_acc: 6.7935e-04 - val_loss: 0.6084 - val_classification_loss: 0.3335 - val_regression_loss: 0.2749 - val_classification_acc: 0.8753 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.57632\n",
      "Epoch 8/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4444 - classification_loss: 0.2675 - regression_loss: 0.1769 - classification_acc: 0.8864 - regression_acc: 5.8877e-04 - val_loss: 0.6206 - val_classification_loss: 0.3287 - val_regression_loss: 0.2919 - val_classification_acc: 0.8878 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57632\n",
      "Epoch 9/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4394 - classification_loss: 0.2665 - regression_loss: 0.1728 - classification_acc: 0.8868 - regression_acc: 6.3406e-04 - val_loss: 0.6302 - val_classification_loss: 0.3345 - val_regression_loss: 0.2956 - val_classification_acc: 0.8774 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57632\n",
      "Epoch 10/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4383 - classification_loss: 0.2656 - regression_loss: 0.1728 - classification_acc: 0.8872 - regression_acc: 6.3406e-04 - val_loss: 0.6139 - val_classification_loss: 0.3317 - val_regression_loss: 0.2822 - val_classification_acc: 0.8769 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57632\n",
      "Epoch 11/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4375 - classification_loss: 0.2651 - regression_loss: 0.1724 - classification_acc: 0.8874 - regression_acc: 5.6613e-04 - val_loss: 0.6176 - val_classification_loss: 0.3345 - val_regression_loss: 0.2831 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57632\n",
      "Epoch 12/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4379 - classification_loss: 0.2659 - regression_loss: 0.1720 - classification_acc: 0.8872 - regression_acc: 6.3406e-04 - val_loss: 0.6158 - val_classification_loss: 0.3276 - val_regression_loss: 0.2882 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57632\n",
      "Epoch 13/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4382 - classification_loss: 0.2664 - regression_loss: 0.1718 - classification_acc: 0.8868 - regression_acc: 6.3406e-04 - val_loss: 0.6185 - val_classification_loss: 0.3341 - val_regression_loss: 0.2843 - val_classification_acc: 0.8765 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57632\n",
      "Epoch 14/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4374 - classification_loss: 0.2656 - regression_loss: 0.1718 - classification_acc: 0.8871 - regression_acc: 5.8877e-04 - val_loss: 0.6162 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.57632\n",
      "Epoch 15/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4374 - classification_loss: 0.2655 - regression_loss: 0.1719 - classification_acc: 0.8871 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57632\n",
      "Epoch 16/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4377 - classification_loss: 0.2656 - regression_loss: 0.1721 - classification_acc: 0.8874 - regression_acc: 6.3406e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57632\n",
      "Epoch 17/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4385 - classification_loss: 0.2659 - regression_loss: 0.1725 - classification_acc: 0.8870 - regression_acc: 6.3406e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57632\n",
      "Epoch 18/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4380 - classification_loss: 0.2663 - regression_loss: 0.1717 - classification_acc: 0.8870 - regression_acc: 6.1142e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57632\n",
      "Epoch 19/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4375 - classification_loss: 0.2645 - regression_loss: 0.1730 - classification_acc: 0.8878 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57632\n",
      "Epoch 20/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4382 - classification_loss: 0.2665 - regression_loss: 0.1717 - classification_acc: 0.8866 - regression_acc: 5.8877e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.57632\n",
      "Epoch 21/200\n",
      "345/345 [==============================] - 258s 746ms/step - loss: 0.4370 - classification_loss: 0.2653 - regression_loss: 0.1717 - classification_acc: 0.8873 - regression_acc: 6.3406e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.57632\n",
      "Epoch 22/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4375 - classification_loss: 0.2648 - regression_loss: 0.1728 - classification_acc: 0.8874 - regression_acc: 6.3406e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.57632\n",
      "Epoch 23/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4371 - classification_loss: 0.2659 - regression_loss: 0.1712 - classification_acc: 0.8872 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.57632\n",
      "Epoch 24/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4389 - classification_loss: 0.2662 - regression_loss: 0.1727 - classification_acc: 0.8869 - regression_acc: 6.7935e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.57632\n",
      "Epoch 25/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4382 - classification_loss: 0.2666 - regression_loss: 0.1716 - classification_acc: 0.8868 - regression_acc: 5.2084e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.57632\n",
      "Epoch 26/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4373 - classification_loss: 0.2650 - regression_loss: 0.1723 - classification_acc: 0.8875 - regression_acc: 6.3406e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.57632\n",
      "Epoch 27/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4376 - classification_loss: 0.2657 - regression_loss: 0.1719 - classification_acc: 0.8873 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.57632\n",
      "Epoch 28/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4370 - classification_loss: 0.2653 - regression_loss: 0.1717 - classification_acc: 0.8872 - regression_acc: 4.9819e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.57632\n",
      "Epoch 29/200\n",
      "345/345 [==============================] - 257s 746ms/step - loss: 0.4392 - classification_loss: 0.2668 - regression_loss: 0.1724 - classification_acc: 0.8866 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.57632\n",
      "Epoch 30/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4380 - classification_loss: 0.2658 - regression_loss: 0.1722 - classification_acc: 0.8872 - regression_acc: 6.5671e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.57632\n",
      "Epoch 31/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4371 - classification_loss: 0.2656 - regression_loss: 0.1715 - classification_acc: 0.8871 - regression_acc: 5.4348e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.57632\n",
      "Epoch 32/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4362 - classification_loss: 0.2645 - regression_loss: 0.1717 - classification_acc: 0.8878 - regression_acc: 5.6613e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.57632\n",
      "Epoch 33/200\n",
      "345/345 [==============================] - 259s 751ms/step - loss: 0.4386 - classification_loss: 0.2666 - regression_loss: 0.1720 - classification_acc: 0.8868 - regression_acc: 7.0200e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.57632\n",
      "Epoch 34/200\n",
      "345/345 [==============================] - 260s 752ms/step - loss: 0.4377 - classification_loss: 0.2657 - regression_loss: 0.1720 - classification_acc: 0.8870 - regression_acc: 6.1141e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.57632\n",
      "Epoch 35/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4375 - classification_loss: 0.2659 - regression_loss: 0.1716 - classification_acc: 0.8871 - regression_acc: 7.0200e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.57632\n",
      "Epoch 36/200\n",
      "345/345 [==============================] - 259s 751ms/step - loss: 0.4376 - classification_loss: 0.2653 - regression_loss: 0.1723 - classification_acc: 0.8872 - regression_acc: 5.6613e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.57632\n",
      "Epoch 37/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4366 - classification_loss: 0.2648 - regression_loss: 0.1718 - classification_acc: 0.8876 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.57632\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4377 - classification_loss: 0.2667 - regression_loss: 0.1710 - classification_acc: 0.8867 - regression_acc: 6.3406e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.57632\n",
      "Epoch 39/200\n",
      "345/345 [==============================] - 259s 749ms/step - loss: 0.4383 - classification_loss: 0.2652 - regression_loss: 0.1731 - classification_acc: 0.8873 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.57632\n",
      "Epoch 40/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4369 - classification_loss: 0.2658 - regression_loss: 0.1710 - classification_acc: 0.8871 - regression_acc: 6.7935e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.57632\n",
      "Epoch 41/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4386 - classification_loss: 0.2660 - regression_loss: 0.1726 - classification_acc: 0.8870 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.57632\n",
      "Epoch 42/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4379 - classification_loss: 0.2665 - regression_loss: 0.1714 - classification_acc: 0.8869 - regression_acc: 5.8877e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.57632\n",
      "Epoch 43/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4361 - classification_loss: 0.2644 - regression_loss: 0.1717 - classification_acc: 0.8876 - regression_acc: 5.4348e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.57632\n",
      "Epoch 44/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4395 - classification_loss: 0.2667 - regression_loss: 0.1727 - classification_acc: 0.8868 - regression_acc: 5.8877e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.57632\n",
      "Epoch 45/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4369 - classification_loss: 0.2645 - regression_loss: 0.1724 - classification_acc: 0.8879 - regression_acc: 6.7935e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.57632\n",
      "Epoch 46/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4377 - classification_loss: 0.2661 - regression_loss: 0.1716 - classification_acc: 0.8868 - regression_acc: 5.4348e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.57632\n",
      "Epoch 47/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4386 - classification_loss: 0.2662 - regression_loss: 0.1723 - classification_acc: 0.8870 - regression_acc: 6.3406e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.57632\n",
      "Epoch 48/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4368 - classification_loss: 0.2644 - regression_loss: 0.1724 - classification_acc: 0.8878 - regression_acc: 5.2084e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.57632\n",
      "Epoch 49/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4381 - classification_loss: 0.2675 - regression_loss: 0.1706 - classification_acc: 0.8864 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.57632\n",
      "Epoch 50/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4379 - classification_loss: 0.2657 - regression_loss: 0.1721 - classification_acc: 0.8873 - regression_acc: 7.2464e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.57632\n",
      "Epoch 51/200\n",
      "345/345 [==============================] - 260s 754ms/step - loss: 0.4366 - classification_loss: 0.2639 - regression_loss: 0.1727 - classification_acc: 0.8880 - regression_acc: 6.1141e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.57632\n",
      "Epoch 52/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4407 - classification_loss: 0.2677 - regression_loss: 0.1730 - classification_acc: 0.8860 - regression_acc: 6.1142e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.57632\n",
      "Epoch 53/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4368 - classification_loss: 0.2654 - regression_loss: 0.1714 - classification_acc: 0.8875 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.57632\n",
      "Epoch 54/200\n",
      "345/345 [==============================] - 259s 751ms/step - loss: 0.4369 - classification_loss: 0.2654 - regression_loss: 0.1714 - classification_acc: 0.8873 - regression_acc: 5.8877e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.57632\n",
      "Epoch 55/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4372 - classification_loss: 0.2645 - regression_loss: 0.1727 - classification_acc: 0.8878 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.57632\n",
      "Epoch 56/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4387 - classification_loss: 0.2662 - regression_loss: 0.1725 - classification_acc: 0.8868 - regression_acc: 5.8877e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.57632\n",
      "Epoch 57/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4389 - classification_loss: 0.2652 - regression_loss: 0.1737 - classification_acc: 0.8873 - regression_acc: 6.7935e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.57632\n",
      "Epoch 58/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4394 - classification_loss: 0.2683 - regression_loss: 0.1712 - classification_acc: 0.8858 - regression_acc: 6.3406e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.57632\n",
      "Epoch 59/200\n",
      "345/345 [==============================] - 259s 751ms/step - loss: 0.4356 - classification_loss: 0.2637 - regression_loss: 0.1718 - classification_acc: 0.8882 - regression_acc: 5.6613e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.57632\n",
      "Epoch 60/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4389 - classification_loss: 0.2665 - regression_loss: 0.1725 - classification_acc: 0.8866 - regression_acc: 6.3406e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.57632\n",
      "Epoch 61/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4370 - classification_loss: 0.2656 - regression_loss: 0.1714 - classification_acc: 0.8874 - regression_acc: 7.0199e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.57632\n",
      "Epoch 62/200\n",
      "345/345 [==============================] - 258s 747ms/step - loss: 0.4399 - classification_loss: 0.2663 - regression_loss: 0.1736 - classification_acc: 0.8868 - regression_acc: 5.2084e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.57632\n",
      "Epoch 63/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4366 - classification_loss: 0.2659 - regression_loss: 0.1707 - classification_acc: 0.8870 - regression_acc: 6.1142e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.57632\n",
      "Epoch 64/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4389 - classification_loss: 0.2661 - regression_loss: 0.1728 - classification_acc: 0.8870 - regression_acc: 6.5670e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.57632\n",
      "Epoch 65/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4356 - classification_loss: 0.2645 - regression_loss: 0.1712 - classification_acc: 0.8876 - regression_acc: 5.8877e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.57632\n",
      "Epoch 66/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4368 - classification_loss: 0.2650 - regression_loss: 0.1718 - classification_acc: 0.8876 - regression_acc: 7.0200e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57632\n",
      "Epoch 67/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4361 - classification_loss: 0.2641 - regression_loss: 0.1720 - classification_acc: 0.8879 - regression_acc: 5.2084e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57632\n",
      "Epoch 68/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4386 - classification_loss: 0.2669 - regression_loss: 0.1717 - classification_acc: 0.8865 - regression_acc: 5.4348e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.57632\n",
      "Epoch 69/200\n",
      "345/345 [==============================] - 258s 748ms/step - loss: 0.4386 - classification_loss: 0.2665 - regression_loss: 0.1721 - classification_acc: 0.8868 - regression_acc: 7.4728e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.57632\n",
      "Epoch 70/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4373 - classification_loss: 0.2657 - regression_loss: 0.1716 - classification_acc: 0.8871 - regression_acc: 5.8877e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.57632\n",
      "Epoch 71/200\n",
      "345/345 [==============================] - 259s 751ms/step - loss: 0.4380 - classification_loss: 0.2647 - regression_loss: 0.1733 - classification_acc: 0.8877 - regression_acc: 5.6613e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.57632\n",
      "Epoch 72/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4376 - classification_loss: 0.2663 - regression_loss: 0.1713 - classification_acc: 0.8869 - regression_acc: 6.1142e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.57632\n",
      "Epoch 73/200\n",
      "345/345 [==============================] - 258s 749ms/step - loss: 0.4378 - classification_loss: 0.2655 - regression_loss: 0.1723 - classification_acc: 0.8874 - regression_acc: 6.1141e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.57632\n",
      "Epoch 74/200\n",
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4355 - classification_loss: 0.2641 - regression_loss: 0.1714 - classification_acc: 0.8878 - regression_acc: 6.3406e-04 - val_loss: 0.6163 - val_classification_loss: 0.3319 - val_regression_loss: 0.2843 - val_classification_acc: 0.8766 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.57632\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 259s 750ms/step - loss: 0.4414 - classification_loss: 0.2681 - regression_loss: 0.1733 - classification_acc: 0.8860 - regression_acc: 5.2084e-04 - val_loss: 0.6191 - val_classification_loss: 0.3346 - val_regression_loss: 0.2844 - val_classification_acc: 0.8771 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.57632\n",
      "Epoch 76/200\n",
      "345/345 [==============================] - 259s 749ms/step - loss: 0.4361 - classification_loss: 0.2652 - regression_loss: 0.1709 - classification_acc: 0.8875 - regression_acc: 6.7935e-04 - val_loss: 0.6172 - val_classification_loss: 0.3276 - val_regression_loss: 0.2896 - val_classification_acc: 0.8860 - val_regression_acc: 0.0016\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.57632\n",
      "Epoch 77/200\n",
      "345/345 [==============================] - 259s 752ms/step - loss: 0.4392 - classification_loss: 0.2668 - regression_loss: 0.1723 - classification_acc: 0.8869 - regression_acc: 5.4348e-04 - val_loss: 0.6191 - val_classification_loss: 0.3342 - val_regression_loss: 0.2850 - val_classification_acc: 0.8764 - val_regression_acc: 7.9618e-04\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.57632\n",
      "Epoch 78/200\n",
      " 95/345 [=======>......................] - ETA: 3:09 - loss: 0.4312 - classification_loss: 0.2617 - regression_loss: 0.1695 - classification_acc: 0.8893 - regression_acc: 7.4013e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5e6b7556a087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    callbacks=[\n\u001b[1;32m      5\u001b[0m                        \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chpt-4_2.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                    ])\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen, validation_data=test_gen, epochs=200, \n",
    "                    steps_per_epoch=train_len // 128,\n",
    "                   validation_steps=10, use_multiprocessing=False,\n",
    "                   callbacks=[\n",
    "                       ReduceLROnPlateau(patience=2, verbose=1),\n",
    "                       ModelCheckpoint('chpt-4_2.hdf5', verbose=1, save_best_only=True)\n",
    "                   ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
